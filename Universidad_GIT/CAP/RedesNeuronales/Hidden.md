El **hidden** (o **capa oculta**) en una red neuronal es la capa intermedia entre la **entrada (input)** y la **salida (output)**. Su funci贸n principal es **aprender patrones y caracter铆sticas de los datos de entrada** para mejorar la predicci贸n.

---

###  **Ejemplo en el Reconocimiento de D铆gitos**

Sigamos con el ejemplo de la red neuronal que reconoce n煤meros del 0 al 9.

#### **Estructura de la red**

- **Capa de entrada (input):**  
     Representa los p铆xeles de la imagen (ej. una imagen de 28x28 p铆xeles tiene **784** neuronas de entrada).
    
- **Capa oculta (hidden):**  
     Contiene neuronas que procesan la informaci贸n y aprenden caracter铆sticas del n煤mero.  
     En la imagen que compartiste, parece haber **135 neuronas en la capa oculta**.
    
- **Capa de salida (output):**  
     Tiene **10 neuronas**, una por cada n煤mero del 0 al 9.
    

---

###  **驴C贸mo funciona la capa oculta?**

1. **La imagen (input) pasa por la capa oculta.**
    
    - Cada **neurona en la capa oculta** recibe se帽ales de todas las neuronas de entrada.
    - Se aplican **pesos (weights) y bias (bias_h)** para modificar los valores.
    - Luego, se usa una **funci贸n de activaci贸n** (ej. ReLU, Sigmoid, etc.) para generar una nueva representaci贸n de los datos.
2. **La salida de la capa oculta se env铆a a la capa de salida.**
    
    - La informaci贸n procesada se convierte en probabilidades para determinar cu谩l n煤mero es el m谩s probable.

---

###  **Ejemplo Num茅rico**

Supongamos que tenemos:

- Imagen de un **"3"** como entrada.
- La capa oculta tiene **135 neuronas**.
- La red calcula los valores ocultos antes de pasar a la salida:

```
hidden = [0.2, 0.8, 0.1, ..., 0.6]  # 135 valores
```

Estos valores son una **representaci贸n abstracta** de la imagen. La red ha aprendido que ciertas combinaciones de valores en la capa oculta corresponden a un "3".

Despu茅s, estos valores se env铆an a la capa de salida para calcular la predicci贸n final.

---

###  **驴C贸mo se corrige la capa oculta con el backpropagation?**

Si la predicci贸n es incorrecta, la red ajusta sus pesos y **bias_h** en la capa oculta para mejorar en el siguiente intento.

El ajuste se hace con:

Weightsinputhidden=畏ErrorDerivadadeactivacion\Delta Weights_{input-hidden} = -\eta \times Error \times \text{Derivada de activaci贸n} Biash=畏Error\Delta Bias_h = -\eta \times Error

Esto permite que la red aprenda mejor **c贸mo transformar la imagen en una salida correcta**.

---

###  **Conclusi贸n**

La **capa oculta** es el coraz贸n del aprendizaje de una red neuronal. Es donde la red encuentra **patrones y caracter铆sticas** que ayudan a identificar correctamente los n煤meros, letras, im谩genes, etc.

Si no existiera una capa oculta, la red solo podr铆a aprender relaciones muy simples, pero con una **hidden layer** es capaz de generalizar mejor la informaci贸n.

驴Te queda m谩s claro? 