### **Diferencias entre MPI y OpenMP**

MPI (Message Passing Interface) y OpenMP (Open Multi-Processing) son dos modelos de programaci√≥n paralela ampliamente utilizados, pero tienen diferencias clave en su arquitectura, uso y aplicaci√≥n.

|**Caracter√≠stica**|**MPI (Message Passing Interface)**|**OpenMP (Open Multi-Processing)**|
|---|---|---|
|**Modelo de paralelismo**|Paso de mensajes (distribuido)|Compartici√≥n de memoria (multihilo)|
|**Arquitectura**|Se usa en sistemas distribuidos (clusters, supercomputadoras).|Se usa en sistemas de memoria compartida (CPU con m√∫ltiples n√∫cleos).|
|**Comunicaci√≥n entre procesos**|Requiere intercambio de mensajes entre procesos (MPI_Send, MPI_Recv).|Usa memoria compartida, evitando la necesidad de mensajes expl√≠citos.|
|**Escalabilidad**|Escala mejor en supercomputadoras con miles de nodos.|Limitado a un solo nodo con m√∫ltiples n√∫cleos.|
|**Facilidad de uso**|M√°s complejo, requiere gesti√≥n manual de procesos y comunicaci√≥n.|M√°s f√°cil, basado en directivas `#pragma omp`.|
|**Lenguajes compatibles**|C, C++, Fortran.|C, C++, Fortran.|
|**Ejemplo de uso**|Simulaciones cient√≠ficas, computaci√≥n en la nube, Big Data.|Aplicaciones en CPU de m√∫ltiples n√∫cleos, como optimizaci√≥n de c√≥digo en procesadores modernos.|

---


### **Ejemplo en MPI (Distribuido)**

Cada proceso ejecuta el mismo c√≥digo pero maneja datos distintos.

```c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    printf("Proceso %d de %d\n", rank, size);

    MPI_Finalize();
    return 0;
}
```

‚è© **Ejecuci√≥n t√≠pica** en un cl√∫ster:

```sh
mpicc programa.c -o programa
mpirun -np 4 ./programa
```

---

### **Ejemplo en OpenMP (Memoria Compartida)**

Se ejecuta en m√∫ltiples hilos dentro de una CPU.

```c
#include <stdio.h>
#include <omp.h>

int main() {
    #pragma omp parallel
    {
        int id = omp_get_thread_num();
        printf("Hola desde el hilo %d\n", id);
    }
    return 0;
}
```

‚è© **Compilaci√≥n y ejecuci√≥n:**

```sh
gcc -fopenmp programa.c -o programa
./programa
```

---

### **¬øCu√°ndo usar cada uno?**

‚úÖ **Usa MPI si‚Ä¶**

- Necesitas ejecutar en m√∫ltiples nodos o servidores.
- Requieres escalar a cientos o miles de procesos.
- La memoria compartida no es viable (por ejemplo, en un cl√∫ster).

‚úÖ **Usa OpenMP si‚Ä¶**

- Trabajas en una sola m√°quina con m√∫ltiples n√∫cleos.
- Buscas una forma sencilla de paralelizar c√≥digo sin manejar mensajes.
- Quieres mejorar el rendimiento de una aplicaci√≥n en CPU sin grandes cambios.

üìå **¬øY si necesito ambos?** Puedes combinarlos en **programaci√≥n h√≠brida (MPI + OpenMP)** para aprovechar lo mejor de ambos mundos. üöÄ